const tf = require("@tensorflow/tfjs-node");
const fetch = require("node-fetch");
const { imag } = require("@tensorflow/tfjs-node");

const modelUrl =
  "https://storage.googleapis.com/tfjs-models/tfjs/sentiment_cnn_v1/model.json";
const metadataUrl =
  "https://storage.googleapis.com/tfjs-models/tfjs/sentiment_cnn_v1/metadata.json";

const loadModel = async () => {
  return tf.loadLayersModel(modelUrl);
};

const loadMetadata = async () => {
  try {
    const metadataJson = await fetch(metadataUrl);
    const sentimentMetadata = await metadataJson.json();

    const indexFrom = sentimentMetadata.index_from;
    const maxLen = sentimentMetadata.max_len;
    const wordIndex = sentimentMetadata.word_index;
    const vocabularySize = sentimentMetadata.vocabulary_size;

    return { indexFrom, maxLen, wordIndex, vocabularySize };
  } catch (err) {
    console.error(err);
  }
};

/**
 * Peforms pad sequencing so that all sentences have the exact same length before prediction
 * @param {*} sequences List of word values generated by matching sentences with model metadata
 * @param {*} maxLen Maximum length of sequence
 * @param {*} padding Padding mode i.e. pre or post
 * @param {*} truncating Trauncating mode i.e. pre or post
 * @param {*} value Value to pad with
 * @tutorial https://keras.io/api/preprocessing/timeseries/
 */
const pad = (
  sequences,
  maxLen,
  padding = "pre",
  truncating = "pre",
  value = 0
) => {
  return sequences.map((seq) => {
    // truncating
    if (seq.length > maxLen) {
      if (truncating === "pre") {
        seq.splice(0, seq.length - maxLen);
      } else {
        seq.splice(maxLen, seq.length - maxLen);
      }
    }

    // padding
    if (seq.length < maxLen) {
      const padded = [];
      for (let i = 0; i < maxLen - seq.length; i++) {
        padded.push(value);
      }
      if (padding === "pre") {
        seq = padded.concat(seq);
      } else {
        seq = seq.concat(padded);
      }
    }
    return seq;
  });
};

const predict = async () => {
  const text = "I want to kill myself";

  const model = await loadModel();
  const { wordIndex, maxLen, indexFrom, vocabularySize } = await loadMetadata();

  // remove punctuation and split get individual words
  const inputText = text
    .trim()
    .toLowerCase()
    .replace(/(\.|\,|\!)/g, "")
    .split(" ");

  // matches words with metadata value
  const sequence = inputText.map((word) => {
    let wordIdx = wordIndex[word] + indexFrom;

    if (wordIdx > vocabularySize) {
      wordIdx = 2;
    }
    return wordIdx;
  });

  // padding
  const paddedSequence = pad([sequence], maxLen);

  // creates 2d tensor (2D matrix) with consistent length
  const input = tf.tensor2d(paddedSequence, [1, maxLen]);

  const prediction = model.predict(input);
  const score = prediction.dataSync()[0];
  prediction.dispose();

  console.log(text, score);
};

predict();
